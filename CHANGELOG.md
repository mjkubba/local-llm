# Changelog

All notable changes to the Local LLM Extension will be documented in this file.

## [0.1.0] - 2024-11-08

### Initial Release

- Connect to local AI servers with OpenAI-compatible APIs
- Sidebar chat interface with streaming responses
- Model management (list, select, refresh)
- Code actions (explain, improve, generate)
- Text completion support
- Keyboard shortcuts for quick access
- Configurable settings (temperature, tokens, prompts)
- Performance metrics display
- Status bar integration
- Compatible with LM Studio, Ollama, and other OpenAI-compatible servers
